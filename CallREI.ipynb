{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMT2OmC/PXydfa3044wNgd7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BillWorstell/REI/blob/main/CallREI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGc1YcV3YvqQ",
        "outputId": "5deadefb-8db3-41c3-fdf3-b88ce398e72a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mâœ¨ðŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import condacolab\n",
        "condacolab.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAiP9qnZdH3G",
        "outputId": "0c9071cf-c39c-4b64-c4f2-0adaae09d361"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ¨ðŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "GN0AL_2vYuhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioUPlYAucZyd",
        "outputId": "bdca2909-a1c5-4324-98f9-e00e21f30c12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find envinoment.yml"
      ],
      "metadata": {
        "id": "-e2rntLNcoi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/REI-main/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVsy2SP0csXi",
        "outputId": "f9933ed8-e7c1-4e61-fd57-d02ae6ebcdcf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset       demo_train.py    models\tREADME.md     train_bash.sh\n",
            "demo_scripts  environment.yml  physics\trei\t      transforms\n",
            "demo_test.py  images\t       qa.md\tREI-main.zip  utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env update -n base -f /content/drive/MyDrive/REI-main/environment.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5MCJHBMZNMn",
        "outputId": "fb272ace-2fd0-4bd2-af4f-9f20ca83b74e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - pytorch\n",
            " - conda-forge\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\bfailed\n",
            "\n",
            "SpecsConfigurationConflictError: Requested specs conflict with configured specs.\n",
            "  requested specs: \n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - blas==1.0=mkl\n",
            "    - ca-certificates==2020.10.14=0\n",
            "    - certifi==2020.11.8=py36h06a4308_0\n",
            "    - cloudpickle==1.6.0=py_0\n",
            "    - cudatoolkit==10.2.89=hfd86e86_1\n",
            "    - cycler==0.10.0=py_2\n",
            "    - cytoolz==0.11.0=py36h7b6447c_0\n",
            "    - dask-core==2.30.0=py_0\n",
            "    - decorator==4.4.2=py_0\n",
            "    - freetype==2.10.2=h5ab3b9f_0\n",
            "    - h5py==2.10.0=py36hd6299e0_1\n",
            "    - hdf5==1.10.6=hb1b8bf9_0\n",
            "    - imageio==2.9.0=py_0\n",
            "    - intel-openmp==2020.2=254\n",
            "    - joblib==0.17.0=py_0\n",
            "    - jpeg==9b=h024ee3a_2\n",
            "    - kiwisolver==1.2.0=py36hdb11119_0\n",
            "    - lcms2==2.11=h396b838_0\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20191231=h14c3975_1\n",
            "    - libffi==3.3=he6710b0_2\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libgfortran-ng==7.3.0=hdf63c60_0\n",
            "    - libpng==1.6.37=hbc83047_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - libtiff==4.1.0=h2733197_1\n",
            "    - lz4-c==1.9.2=heb0550a_3\n",
            "    - matplotlib==3.3.2=0\n",
            "    - matplotlib-base==3.3.2=py36h5ffbc53_0\n",
            "    - mkl==2020.2=256\n",
            "    - mkl-service==2.3.0=py36he904b0f_0\n",
            "    - mkl_fft==1.2.0=py36h23d657b_0\n",
            "    - mkl_random==1.1.1=py36h0573a6f_0\n",
            "    - ncurses==6.2=he6710b0_1\n",
            "    - networkx==2.5=py_0\n",
            "    - ninja==1.10.1=py36hfd86e86_0\n",
            "    - numpy==1.19.1=py36hbc911f0_0\n",
            "    - numpy-base==1.19.1=py36hfa32c7d_0\n",
            "    - olefile==0.46=py36_0\n",
            "    - openssl==1.1.1h=h7b6447c_0\n",
            "    - pillow==7.2.0=py36hb39fc2d_0\n",
            "    - pip==20.2.3=py36_0\n",
            "    - pyparsing==2.4.7=pyh9f0ad1d_0\n",
            "    - python==3.6.12=hcff3b4d_2\n",
            "    - python-dateutil==2.8.1=py_0\n",
            "    - python_abi==3.6=1_cp36m\n",
            "    - pytorch==1.6.0=py3.6_cuda10.2.89_cudnn7.6.5_0\n",
            "    - pywavelets==1.1.1=py36h7b6447c_2\n",
            "    - pyyaml==5.3.1=py36h7b6447c_1\n",
            "    - readline==8.0=h7b6447c_0\n",
            "    - scikit-image==0.16.2=py36h0573a6f_0\n",
            "    - scikit-learn==0.23.2=py36h0573a6f_0\n",
            "    - scipy==1.5.2=py36h0b6359f_0\n",
            "    - setuptools==50.3.0=py36hb0f4dca_1\n",
            "    - six==1.15.0=py_0\n",
            "    - sqlite==3.33.0=h62c20be_0\n",
            "    - threadpoolctl==2.1.0=pyh5ca1d4c_0\n",
            "    - tk==8.6.10=hbc83047_0\n",
            "    - toolz==0.11.1=py_0\n",
            "    - torchvision==0.7.0=py36_cu102\n",
            "    - tornado==6.0.4=py36h8c4c3a4_1\n",
            "    - wheel==0.35.1=py_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.2.5=h7b6447c_0\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "    - zstd==1.4.5=h9ceee32_0\n",
            "  pinned specs: \n",
            "    - cuda-version=12\n",
            "    - python=3.10\n",
            "    - python_abi=3.10[build=*cp310*]\n",
            "Use 'conda config --show-sources' to look for 'pinned_specs' and 'track_features'\n",
            "configuration parameters.  Pinned specs may also be defined in the file\n",
            "/usr/local/conda-meta/pinned.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for demo_ct.py"
      ],
      "metadata": {
        "id": "XY1MLdl1gOfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltr /content/drive/MyDrive/REI-main/demo_scripts/demo_ct.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QENOKP7egPOK",
        "outputId": "11f9bdd3-5230-4dba-bbb5-63519bfeca30"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 1481 Apr  5 18:20 /content/drive/MyDrive/REI-main/demo_scripts/demo_ct.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltr ./sample_data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3ecfpEig80U",
        "outputId": "add88471-e52a-491d-d52b-617ff65666dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 55504\n",
            "-rwxr-xr-x 1 root root      930 Jan  1  2000 README.md\n",
            "-rwxr-xr-x 1 root root     1697 Jan  1  2000 anscombe.json\n",
            "-rw-r--r-- 1 root root  1706430 Apr  5 13:21 california_housing_train.csv\n",
            "-rw-r--r-- 1 root root   301141 Apr  5 13:21 california_housing_test.csv\n",
            "-rw-r--r-- 1 root root 36523880 Apr  5 13:21 mnist_train_small.csv\n",
            "-rw-r--r-- 1 root root 18289443 Apr  5 13:21 mnist_test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get REI version from github"
      ],
      "metadata": {
        "id": "sDpvkBr6TsDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls -ltr /content/drive/MyDrive/REI-main/physics\n",
        "!ls -ltr /content/drive/MyDrive/REI-main/rei/closure\n",
        "!ls -ltr /content/drive/MyDrive/REI-main/demo_scripts/demo_ct.py\n",
        "!ls -ltr /content/drive/MyDrive/REI-main/rei/rei.py\n",
        "!ls -ltr /content/drive/MyDrive/REI-main/models/unet.py"
      ],
      "metadata": {
        "id": "z5oCMfOWUL3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f6d9b4-ef98-4678-c06e-e21bbfb963b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "total 13\n",
            "-rw------- 1 root root 2002 Apr  5 18:20 mri.py\n",
            "-rw------- 1 root root 2104 Apr  5 18:20 mask_4x.pth.tar\n",
            "-rw------- 1 root root 2104 Apr  5 18:20 inpainting.py\n",
            "-rw------- 1 root root 1393 Apr  5 18:20 ct.py\n",
            "drwx------ 2 root root 4096 Apr  5 18:21 radon\n",
            "total 16\n",
            "-rw------- 1 root root 1743 Apr  5 18:20 supervised.py\n",
            "-rw------- 1 root root 3859 Apr  5 18:20 rei_end2end.py\n",
            "-rw------- 1 root root 3232 Apr  5 18:20 rei_end2end_ct.py\n",
            "-rw------- 1 root root 2380 Apr  5 18:20 ei_end2end.py\n",
            "drwx------ 2 root root 4096 Apr  5 18:21 __pycache__\n",
            "-rw------- 1 root root 1481 Apr  5 18:20 /content/drive/MyDrive/REI-main/demo_scripts/demo_ct.py\n",
            "-rw------- 1 root root 8561 Apr  5 18:20 /content/drive/MyDrive/REI-main/rei/rei.py\n",
            "-rw------- 1 root root 3283 Apr  5 18:20 /content/drive/MyDrive/REI-main/models/unet.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqPWc2KmVYUm",
        "outputId": "c22aca97-b4aa-4bbb-975a-d56d624daf0a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch\n",
            "  Using cached torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch) (3.3)\n",
            "Collecting jinja2 (from torch)\n",
            "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/site-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/site-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
            "Using cached torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "Installing collected packages: nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
            "Successfully installed jinja2-3.1.3 nvidia-cudnn-cu12-8.9.2.26 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 torch-2.2.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting numpy\n",
            "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Installing collected packages: numpy\n",
            "Successfully installed numpy-1.26.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3  /content/drive/MyDrive/REI-main/models/unet.py"
      ],
      "metadata": {
        "id": "OAgN2mW0v3Ik"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!python3  /content/drive/MyDrive/REI-main/rei/rei.py\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "\n",
        "!python3 /content/drive/MyDrive/REI-main/models/unet.py\n",
        "!python3 /content/drive/MyDrive/REI-main/utils/metric.py\n",
        "\n",
        "#!python3 /content/drive/MyDrive/REI-main/rei/closure/rei_end2end.py\n",
        "#!python3 /content/drive/MyDrive/REI-main/rei/closure/rei_end2end_ct.py\n",
        "#!python3 /content/drive/MyDrive/REI-main/rei/closure/ei_end2end.py\n",
        "#!python3 /content/drive/MyDrive/REI-main/rei/closure/supervised.py"
      ],
      "metadata": {
        "id": "PCguRalWv4XL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Edited /content/drive/MyDrive/REI-main/rei/closure/rei_end2end.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "#from utils.metric import cal_psnr, cal_mse, cal_psnr_complex\n",
        "\n",
        "def closure_rei_end2end(net, dataloader, physics, transform, optimizer,\n",
        "                        criterion, alpha, tau, dtype, device, reportpsnr=False):\n",
        "    assert physics.name in ['mri', 'inpainting'], \\\n",
        "        'This scripts only work ' \\\n",
        "        'for Gaussian noise (e.g. in MRI) ' \\\n",
        "        'and Poission noise (e.g. in Inpainting)!'\n",
        "\n",
        "    loss_sure_seq, loss_req_seq, loss_seq, psnr_seq, mse_seq = [], [], [], [], []\n",
        "\n",
        "    cal_psnr_fn = cal_psnr_complex if physics.name in ['mri'] else cal_psnr\n",
        "    f = lambda y: net(physics.A_dagger(y))\n",
        "\n",
        "    for i, x in enumerate(dataloader):\n",
        "        x = x[0] if isinstance(x, list) else x\n",
        "        if len(x.shape)==5:\n",
        "            N,n_crops,C,H,W =x.shape\n",
        "            x = x.view(N*n_crops, C,H,W)\n",
        "        if len(x.shape)==3:\n",
        "            x = x.unsqueeze(1)\n",
        "        x = x.type(dtype).to(device) # GT\n",
        "\n",
        "        y0 = physics.A(x, add_noise=True)\n",
        "        x0 = physics.A_dagger(y0) #A^+y, or FBP in CT\n",
        "\n",
        "        x1 = net(x0)\n",
        "        y1 = physics.A(x1)\n",
        "\n",
        "        # SURE-based unbiased estimator to the clean measurement consistency loss\n",
        "        if physics.noise_model['noise_type']=='g':\n",
        "            sigma2 = physics.noise_model['sigma'] ** 2\n",
        "            # generate a random vector b\n",
        "            b = torch.randn_like(x0)\n",
        "            if physics.name in ['mri', 'inpainting']:\n",
        "                b = physics.A(b)\n",
        "\n",
        "            y2 = physics.A(net(physics.A_dagger(y0 + tau * b)))\n",
        "\n",
        "            # compute batch size K\n",
        "            K = y0.shape[0]\n",
        "            # compute n (dimension of x)\n",
        "            n = y0.shape[-1]*y0.shape[-2]*y0.shape[-3]\n",
        "\n",
        "            # compute m (dimension of y)\n",
        "            if physics.name=='mri':\n",
        "                m = n /physics.acceleration # dim(y)\n",
        "            if physics.name == 'inpainting':\n",
        "                m = n * (1 - physics.mask_rate)\n",
        "\n",
        "            # compute loss_sure\n",
        "            loss_sure = torch.sum((y1 - y0).pow(2)) / (K * m) - sigma2 \\\n",
        "                        + (2 * sigma2 / (tau *m * K)) * (b * (y2 - y1)).sum()\n",
        "\n",
        "        if physics.noise_model['noise_type'] == 'p':\n",
        "            # generate a random vector b\n",
        "            b = torch.rand_like(y0) > 0.5\n",
        "            b = (2 * b.int() - 1) * 1.0  # binary [-1, 1]\n",
        "            b = physics.A(b * 1.0)\n",
        "            if physics.name in ['mri', 'inpainting']:\n",
        "                b = physics.A(b)\n",
        "\n",
        "            y2 = physics.A(net(physics.A_dagger(y0 + tau * b)))\n",
        "\n",
        "            # compute batch size K\n",
        "            K = y0.shape[0]\n",
        "            # compute n (dimension of x)\n",
        "            n = y0.shape[-1]*y0.shape[-2]*y0.shape[-3]\n",
        "\n",
        "            # compute m (dimension of y)\n",
        "            if physics.name=='mri':\n",
        "                m = n /physics.acceleration # dim(y)\n",
        "            if physics.name == 'inpainting':\n",
        "                m = n * (1 - physics.mask_rate)\n",
        "\n",
        "            loss_sure = torch.sum((y1 - y0).pow(2)) / (K * m) \\\n",
        "                        - physics.noise_model['gamma'] * y0.sum() / (K * m) \\\n",
        "                        + 2 * physics.noise_model['gamma'] / (tau * K * m) * ((b * y0) * (y2 - y1)).sum()\n",
        "\n",
        "        # REQ (EI with noisy input)\n",
        "        x2 = transform.apply(x1)\n",
        "        x3 = f(physics.A(x2, add_noise=True))\n",
        "        # compute loss_req\n",
        "        loss_req = alpha['req'] * criterion(x3, x2)\n",
        "\n",
        "        loss = loss_sure + loss_req\n",
        "\n",
        "        loss_sure_seq.append(loss_sure.item())\n",
        "        loss_req_seq.append(loss_req.item())\n",
        "        loss_seq.append(loss.item())\n",
        "\n",
        "        if reportpsnr:\n",
        "            psnr_seq.append(cal_psnr_fn(x1, x))\n",
        "            mse_seq.append(cal_mse(x1, x))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_closure = [np.mean(loss_sure_seq), np.mean(loss_req_seq), np.mean(loss_seq)]\n",
        "\n",
        "    if reportpsnr:\n",
        "        loss_closure.append(np.mean(psnr_seq))\n",
        "        loss_closure.append(np.mean(mse_seq))\n",
        "\n",
        "    return loss_closure"
      ],
      "metadata": {
        "id": "LMyatitfA1MB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Edited /content/drive/MyDrive/REI-main/rei/closure/ei_end2end.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "#from utils.metric import cal_psnr, cal_mse, cal_psnr_complex\n",
        "\n",
        "def closure_ei_end2end(net, dataloader, physics, transform, optimizer,\n",
        "                       criterion, alpha, dtype, device, report_psnr):\n",
        "\n",
        "    loss_mc_seq, loss_eq_seq, loss_seq, psnr_seq, mse_seq = [], [], [], [], []\n",
        "    cal_psnr_fn = cal_psnr_complex if physics.name in ['mri'] else cal_psnr\n",
        "\n",
        "    if physics.name in ['ct']:\n",
        "        norm = lambda x: (x - physics.MIN) / (physics.MAX - physics.MIN)\n",
        "        f = lambda fbp: net(norm(fbp)) * (physics.MAX - physics.MIN) + physics.MIN\n",
        "    else:\n",
        "        f = lambda y: net(physics.A_dagger(y))\n",
        "\n",
        "    for i, x in enumerate(dataloader):\n",
        "        x = x[0] if isinstance(x, list) else x\n",
        "        x = x.unsqueeze(1) if len(x.shape)==3 else x\n",
        "        x = x.type(dtype).to(device) # GT\n",
        "\n",
        "        if physics.name in ['ct']:\n",
        "            x = x * (physics.MAX - physics.MIN) + physics.MIN\n",
        "\n",
        "            meas0 = physics.A(x, add_noise=True)\n",
        "\n",
        "            s_mpg = torch.log(physics.I0 / meas0)\n",
        "            fbp_mpg = physics.iradon(s_mpg)\n",
        "\n",
        "            x1 = f(fbp_mpg)\n",
        "            meas1 = physics.A(x1)\n",
        "\n",
        "            loss_mc = alpha['mc'] * criterion(meas1, meas0)\n",
        "\n",
        "            # EI: x2, x3\n",
        "            x2 = transform.apply(x1)\n",
        "            meas2 = physics.A(x2)\n",
        "            s2 = torch.log(physics.I0 / meas2)\n",
        "            fbp_2 = physics.iradon(s2)\n",
        "            x3 = f(fbp_2)\n",
        "\n",
        "            loss_eq = alpha['eq'] * criterion(norm(x3), norm(x2))\n",
        "\n",
        "        else:\n",
        "            y0 = physics.A(x, add_noise=True)\n",
        "            x1 = f(y0)\n",
        "            y1 = physics.A(x1)\n",
        "\n",
        "            loss_mc = alpha['mc'] * criterion(y1, y0)\n",
        "\n",
        "            # EI: x2, x3\n",
        "            x2 = transform.apply(x1)\n",
        "            x3 = f(physics.A(x2))\n",
        "            # loss EI\n",
        "            loss_eq = alpha['eq'] * criterion(x3, x2)\n",
        "\n",
        "        loss = loss_mc + loss_eq\n",
        "\n",
        "        loss_mc_seq.append(loss_mc.item())\n",
        "        loss_eq_seq.append(loss_eq.item())\n",
        "        loss_seq.append(loss.item())\n",
        "\n",
        "        if report_psnr:\n",
        "            psnr_seq.append(cal_psnr_fn(x1, x))\n",
        "            mse_seq.append(cal_mse(x1, x))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_closure = [np.mean(loss_mc_seq), np.mean(loss_eq_seq), np.mean(loss_seq)]\n",
        "    if report_psnr:\n",
        "        loss_closure.append(np.mean(psnr_seq))\n",
        "        loss_closure.append(np.mean(mse_seq))\n",
        "\n",
        "    return loss_closure"
      ],
      "metadata": {
        "id": "QaZHcSDEBV6h"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Edited /content/drive/MyDrive/REI-main/rei/closure/rei_end2end_ct.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "#from utils.metric import cal_psnr, cal_mse\n",
        "\n",
        "def closure_rei_end2end_ct(net, dataloader, physics, transform, optimizer,\n",
        "                        criterion, alpha, tau, dtype, device, reportpsnr=False,):\n",
        "    loss_sure_seq, loss_req_seq, loss_seq, psnr_seq, mse_seq = [], [], [], [], []\n",
        "\n",
        "    assert physics.name=='ct', 'This scripts only work for MPG noise in the CT task!'\n",
        "\n",
        "    norm = lambda x: (x - physics.MIN) / (physics.MAX - physics.MIN)\n",
        "    f = lambda fbp: net(norm(fbp)) * (physics.MAX - physics.MIN) + physics.MIN\n",
        "\n",
        "    for i, x in enumerate(dataloader):\n",
        "        x = x[0] if isinstance(x, list) else x\n",
        "        if len(x.shape)==5:\n",
        "            N,n_crops,C,H,W =x.shape\n",
        "            x = x.view(N*n_crops, C,H,W)\n",
        "        if len(x.shape)==3:\n",
        "            x = x.unsqueeze(1)\n",
        "        x = x.type(dtype).to(device) # GT\n",
        "        x = x * (physics.MAX - physics.MIN) + physics.MIN # normalize data\n",
        "\n",
        "        meas0 = physics.A(x, add_noise=True)\n",
        "\n",
        "        s_mpg = torch.log(physics.I0 / meas0)\n",
        "        fbp_mpg = physics.iradon(s_mpg)\n",
        "\n",
        "        x1 = f(fbp_mpg)\n",
        "\n",
        "        meas1 = physics.A(x1)\n",
        "\n",
        "        # SURE-based unbiased estimator to the clean measurement consistency loss\n",
        "        if physics.noise_model['noise_type'] == 'mpg':\n",
        "            sigma2 = physics.noise_model['sigma'] ** 2\n",
        "            b1 = torch.randn_like(meas0)\n",
        "            b2 = torch.rand_like(meas0) > 0.5\n",
        "            b2 = (2 * b2.int() - 1) * 1.0  # binary [-1, 1]\n",
        "\n",
        "            fbp_2 = physics.iradon(torch.log(physics.I0 / (meas0 + tau * b1)))\n",
        "            fbp_2p = physics.iradon(torch.log(physics.I0 / (meas0 + tau * b2)))\n",
        "            fbp_2n = physics.iradon(torch.log(physics.I0 / (meas0 - tau * b2)))\n",
        "\n",
        "            meas2 = physics.A(f(fbp_2))\n",
        "            meas2p = physics.A(f(fbp_2p))\n",
        "            meas2n = physics.A(f(fbp_2n))\n",
        "\n",
        "            K = meas0.shape[0]  # batch size\n",
        "            m = meas0.shape[-1] * meas0.shape[-2] * meas0.shape[-3] # dimension of y\n",
        "\n",
        "            loss_A = torch.sum((meas1 - meas0).pow(2)) / (K * m) - sigma2\n",
        "            loss_div1 = 2 / (tau * K * m) * ((b1 * (physics.noise_model['gamma'] * meas0 + sigma2)) * (meas2 - meas1)).sum()\n",
        "            loss_div2 = 2 * sigma2 * physics.noise_model['gamma'] / (tau ** 2 * K * m) * (b2 * (meas2p + meas2n - 2 * meas1)).sum()\n",
        "\n",
        "            loss_sure = alpha['sure'] * (loss_A + loss_div1 + loss_div2)\n",
        "\n",
        "        # REQ (EI with noisy input)\n",
        "        x2 = transform.apply(x1)\n",
        "        meas_x2 = physics.A(x2, add_noise=True)\n",
        "        fbp_x2 = physics.iradon(torch.log(physics.I0 / meas_x2))\n",
        "        x3 = f(fbp_x2)\n",
        "\n",
        "        # compute loss_req\n",
        "        loss_req = alpha['req'] * criterion(norm(x3), norm(x2))\n",
        "\n",
        "        loss = loss_sure + loss_req\n",
        "\n",
        "        loss_sure_seq.append(loss_sure.item())\n",
        "        loss_req_seq.append(loss_req.item())\n",
        "        loss_seq.append(loss.item())\n",
        "\n",
        "        if reportpsnr:\n",
        "            psnr_seq.append(cal_psnr(x1, x))\n",
        "            mse_seq.append(cal_mse(x1, x))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_closure = [np.mean(loss_sure_seq), np.mean(loss_req_seq), np.mean(loss_seq)]\n",
        "\n",
        "    if reportpsnr:\n",
        "        loss_closure.append(np.mean(psnr_seq))\n",
        "        loss_closure.append(np.mean(mse_seq))\n",
        "\n",
        "    return loss_closure"
      ],
      "metadata": {
        "id": "-GCHpUt3B-kl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Edited /content/drive/MyDrive/REI-main/rei/closure/supervised.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "#from utils.metric import cal_psnr, cal_mse, cal_psnr_complex\n",
        "\n",
        "\n",
        "def closure_supervised(net, dataloader, physics, optimizer,\n",
        "                       criterion, dtype, device, reportpsnr=False):\n",
        "    loss_seq, psnr_seq, mse_seq = [], [], []\n",
        "\n",
        "    cal_psnr_fn = cal_psnr_complex if physics.name in ['mri'] else cal_psnr\n",
        "\n",
        "    if physics.name in ['ct']:\n",
        "        norm = lambda x: (x - physics.MIN) / (physics.MAX - physics.MIN)\n",
        "        f = lambda fbp: net(norm(fbp)) * (physics.MAX - physics.MIN) + physics.MIN\n",
        "    else:\n",
        "        f = lambda y: net(physics.A_dagger(y))\n",
        "\n",
        "    for i, x in enumerate(dataloader):\n",
        "        x = x[0] if isinstance(x, list) else x\n",
        "\n",
        "        if len(x.shape) == 5:\n",
        "            N, n_crops, C, H, W = x.shape\n",
        "            x = x.view(N * n_crops, C, H, W)\n",
        "\n",
        "        if len(x.shape) == 3:\n",
        "            x = x.unsqueeze(1)\n",
        "        x = x.type(dtype).to(device)\n",
        "\n",
        "        if physics.name in ['ct']:\n",
        "            x = x * (physics.MAX - physics.MIN) + physics.MIN\n",
        "            meas0 = physics.A(x, add_noise=True)\n",
        "            s_mpg = torch.log(physics.I0 / meas0)\n",
        "            fbp_mpg = physics.iradon(s_mpg)\n",
        "            x1 = f(fbp_mpg)\n",
        "\n",
        "            loss = criterion(norm(x1), norm(x))\n",
        "\n",
        "        else:\n",
        "            y0 = physics.A(x, add_noise=True)\n",
        "            x1 = f(y0)\n",
        "\n",
        "            loss = criterion(x1, x)\n",
        "\n",
        "        loss_seq.append(loss.item())\n",
        "\n",
        "        if reportpsnr:\n",
        "            psnr_seq.append(cal_psnr_fn(x1, x))\n",
        "            mse_seq.append(cal_mse(x1, x))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_closure = [np.mean(loss_seq)]\n",
        "\n",
        "    if reportpsnr:\n",
        "        loss_closure.append(np.mean(psnr_seq))\n",
        "        loss_closure.append(np.mean(mse_seq))\n",
        "\n",
        "    return loss_closure"
      ],
      "metadata": {
        "id": "rvlP2_lBCS3-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/drive/MyDrive/REI-main/utils/nn.py\n",
        "!python3 /content/drive/MyDrive/REI-main/utils/logger.py"
      ],
      "metadata": {
        "id": "go_HzY1R4mjV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Edited /content/drive/MyDrive/REI-main/rei/rei.py\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "#from models.unet import UNet\n",
        "\n",
        "#from .closure.rei_end2end import closure_rei_end2end\n",
        "#from .closure.rei_end2end_ct import closure_rei_end2end_ct\n",
        "#from .closure.ei_end2end import closure_ei_end2end\n",
        "#from .closure.supervised import closure_supervised\n",
        "\n",
        "#from utils.nn import adjust_learning_rate\n",
        "#from utils.logger import get_timestamp, LOG\n",
        "\n",
        "\n",
        "class REI(object):\n",
        "    def __init__(self, in_channels, out_channels, img_width, img_height, dtype, device):\n",
        "        \"\"\"\n",
        "        Robust Equivariant Imaging\n",
        "        \"\"\"\n",
        "        super(REI, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "\n",
        "        self.dtype = dtype\n",
        "        self.device = device\n",
        "\n",
        "    def train_rei(self, dataloader, physics, transform, epochs, lr, alpha, ckp_interval,\n",
        "                  schedule, pretrained, lr_cos, save_ckp, tau, report_psnr, args):\n",
        "\n",
        "        save_path = './ckp/{}_rei_{}_{}_sigma{}_gamma{}'\\\n",
        "            .format(get_timestamp(), physics.name,\n",
        "                    physics.noise_model['noise_type'],\n",
        "                    physics.noise_model['sigma'],\n",
        "                    physics.noise_model['gamma'])\n",
        "        if physics.name=='ct':\n",
        "            save_path += '_I0_{}'.format(physics.I0)\n",
        "            closure_rei = closure_rei_end2end_ct\n",
        "        else:\n",
        "            closure_rei = closure_rei_end2end\n",
        "\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "        generator = UNet(in_channels=self.in_channels,\n",
        "                         out_channels=self.out_channels,\n",
        "                         compact=4, residual=True,\n",
        "                         circular_padding=True, cat=True).to(self.device)\n",
        "\n",
        "        if pretrained:\n",
        "            checkpoint = torch.load(pretrained, map_location=self.device)\n",
        "            generator.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "        criterion = torch.nn.MSELoss().to(self.device)\n",
        "        optimizer = Adam(generator.parameters(), lr=lr['G'], weight_decay=lr['WD'])\n",
        "\n",
        "        log = LOG(save_path, filename='training_loss',\n",
        "                  field_name=['epoch', 'loss_sure', 'loss_req', 'loss_total', 'psnr', 'mse'])\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            adjust_learning_rate(optimizer, epoch, lr['G'], lr_cos, epochs, schedule)\n",
        "\n",
        "            loss = closure_rei(generator, dataloader, physics, transform, optimizer,\n",
        "                               criterion, alpha, tau, self.dtype, self.device, report_psnr)\n",
        "\n",
        "            log.record(epoch + 1, *loss)\n",
        "            print('{}\\tEpoch[{}/{}]\\tsure={:.4e}\\treq={:.4e}\\tloss={:.4e}\\tpsnr={:.4f}\\tmse={:.4e}'\n",
        "                  .format(get_timestamp(), epoch, epochs, *loss))\n",
        "\n",
        "            if save_ckp:\n",
        "                if epoch >0 and epoch % ckp_interval == 0:\n",
        "                    state = {'epoch': epoch,\n",
        "                             'state_dict': generator.state_dict(),\n",
        "                             'optimizer': optimizer.state_dict(),\n",
        "                             'args':args.__dict__}\n",
        "                    torch.save(state, os.path.join(save_path, 'ckp_{}.pth.tar'.format(epoch)))\n",
        "\n",
        "            if epoch + 1 == epochs:\n",
        "                state = {'epoch': epoch,\n",
        "                         'state_dict': generator.state_dict(),\n",
        "                         'optimizer': optimizer.state_dict(),\n",
        "                         'args':args.__dict__}\n",
        "                torch.save(state, os.path.join(save_path, 'ckp_{}.pth.tar'.format(epoch)))\n",
        "        log.close()\n",
        "\n",
        "    def train_ei(self, dataloader, physics, transform, epochs, lr, alpha, ckp_interval,\n",
        "                  schedule, pretrained, lr_cos, save_ckp, report_psnr, args):\n",
        "\n",
        "        save_path = './ckp/{}_ei_{}_{}_sigma{}_gamma{}' \\\n",
        "            .format(get_timestamp(), physics.name,\n",
        "                    physics.noise_model['noise_type'],\n",
        "                    physics.noise_model['sigma'],\n",
        "                    physics.noise_model['gamma'])\n",
        "        if physics.name == 'ct':\n",
        "            save_path += '_I0_{}'.format(physics.I0)\n",
        "\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "        generator = UNet(in_channels=self.in_channels,\n",
        "                         out_channels=self.out_channels,\n",
        "                         compact=4, residual=True,\n",
        "                         circular_padding=True, cat=True).to(self.device)\n",
        "\n",
        "        if pretrained:\n",
        "            checkpoint = torch.load(pretrained, map_location=self.device)\n",
        "            generator.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "        criterion = torch.nn.MSELoss().to(self.device)\n",
        "        optimizer = Adam(generator.parameters(), lr=lr['G'], weight_decay=lr['WD'])\n",
        "\n",
        "        log = LOG(save_path, filename='training_loss',\n",
        "                  field_name=['epoch', 'loss_mc', 'loss_eq', 'loss_total', 'psnr',\n",
        "                              'mse'])\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            adjust_learning_rate(optimizer, epoch, lr['G'], lr_cos, epochs, schedule)\n",
        "\n",
        "            loss = closure_ei_end2end(generator, dataloader, physics, transform, optimizer,\n",
        "                               criterion, alpha, self.dtype, self.device, report_psnr)\n",
        "\n",
        "            log.record(epoch + 1, *loss)\n",
        "            print(\n",
        "                '{}\\tEpoch[{}/{}]\\tmc={:.4e}\\teq={:.4e}\\tloss={:.4e}\\tpsnr={:.4f}\\tmse={:.4e}'\n",
        "                .format(get_timestamp(), epoch, epochs, *loss))\n",
        "\n",
        "            if save_ckp:\n",
        "                if epoch > 0 and epoch % ckp_interval == 0:\n",
        "                    state = {'epoch': epoch,\n",
        "                             'state_dict': generator.state_dict(),\n",
        "                             'optimizer': optimizer.state_dict(),\n",
        "                             'args': args.__dict__}\n",
        "                    torch.save(state,\n",
        "                               os.path.join(save_path, 'ckp_{}.pth.tar'.format(epoch)))\n",
        "\n",
        "            if epoch + 1 == epochs:\n",
        "                state = {'epoch': epoch,\n",
        "                         'state_dict': generator.state_dict(),\n",
        "                         'optimizer': optimizer.state_dict(),\n",
        "                         'args': args.__dict__}\n",
        "                torch.save(state, os.path.join(save_path, 'ckp_{}.pth.tar'.format(epoch)))\n",
        "        log.close()\n",
        "\n",
        "    def train_sup(self, dataloader, physics, epochs, lr, ckp_interval,\n",
        "                  schedule, pretrained, lr_cos, save_ckp, report_psnr, args):\n",
        "\n",
        "        save_path = './ckp/{}_sup_{}_{}_sigma{}_gamma{}' \\\n",
        "            .format(get_timestamp(), physics.name,\n",
        "                    physics.noise_model['noise_type'],\n",
        "                    physics.noise_model['sigma'],\n",
        "                    physics.noise_model['gamma'])\n",
        "        if physics.name == 'ct':\n",
        "            save_path += '_I0_{}'.format(physics.I0)\n",
        "\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "        generator = UNet(in_channels=self.in_channels,\n",
        "                         out_channels=self.out_channels,\n",
        "                         compact=4, residual=True,\n",
        "                         circular_padding=True, cat=True).to(self.device)\n",
        "\n",
        "        if pretrained:\n",
        "            checkpoint = torch.load(pretrained, map_location=self.device)\n",
        "            generator.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "        criterion = torch.nn.MSELoss().to(self.device)\n",
        "        optimizer = Adam(generator.parameters(), lr=lr['G'], weight_decay=lr['WD'])\n",
        "\n",
        "        log = LOG(save_path, filename='training_loss',\n",
        "                  field_name=['epoch', 'loss_total', 'psnr', 'mse'])\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            adjust_learning_rate(optimizer, epoch, lr['G'], lr_cos, epochs, schedule)\n",
        "\n",
        "            loss = closure_supervised(generator, dataloader, physics, optimizer,\n",
        "                                      criterion, self.dtype, self.device, report_psnr)\n",
        "\n",
        "            log.record(epoch + 1, *loss)\n",
        "            print(\n",
        "                '{}\\tEpoch[{}/{}]\\tloss={:.4e}\\tpsnr={:.4f}\\tmse={:.4e}'\n",
        "                .format(get_timestamp(), epoch, epochs, *loss))\n",
        "\n",
        "            if save_ckp:\n",
        "                if epoch > 0 and epoch % ckp_interval == 0:\n",
        "                    state = {'epoch': epoch,\n",
        "                             'state_dict': generator.state_dict(),\n",
        "                             'optimizer': optimizer.state_dict(),\n",
        "                             'args': args.__dict__}\n",
        "                    torch.save(state,\n",
        "                               os.path.join(save_path, 'ckp_{}.pth.tar'.format(epoch)))\n",
        "\n",
        "            if epoch + 1 == epochs:\n",
        "                state = {'epoch': epoch,\n",
        "                         'state_dict': generator.state_dict(),\n",
        "                         'optimizer': optimizer.state_dict(),\n",
        "                         'args': args.__dict__}\n",
        "                torch.save(state, os.path.join(save_path, 'ckp_{}.pth.tar'.format(epoch)))\n",
        "        log.close()\n"
      ],
      "metadata": {
        "id": "Utzr7uBNDaWC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6F-BTS12EBlE"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}